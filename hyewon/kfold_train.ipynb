{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas_streaming.df import train_test_apart_stratify\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import easydict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.utils.data as data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, CenterCrop, RandomHorizontalFlip\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm import notebook\n",
    "import gc\n",
    "import random\n",
    "import copy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# fix seed\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    동일한 조건으로 학습을 할 때, 동일한 결과를 얻기 위해 seed를 고정시킵니다.\n",
    "    \n",
    "    Args:\n",
    "        seed: seed 정수값\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "seed_everything(42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Base Model\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import timm\n",
    "class EfficientNet5(nn.Module):\n",
    "    def __init__(self, class_n=18):\n",
    "        super().__init__()\n",
    "        self.model = EfficientNet.from_pretrained('efficientnet-b5',class_n)\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "class swinLargeModel(nn.Module):\n",
    "    def __init__(self, class_n=18):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('swin_large_patch4_window7_224', pretrained=True)\n",
    "        self.classify = torch.nn.Linear(in_features=1000,out_features=class_n)        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        x = self.classify(x)\n",
    "        return x\n",
    "    \n",
    "class caitBaseModel(nn.Module):\n",
    "    def __init__(self, class_n=18):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('cait_s24_224',pretrained=True)\n",
    "        self.classify = torch.nn.Linear(in_features=1000,out_features=class_n)        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        x = self.classify(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Load"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class MaskLabels:\n",
    "    mask = 0\n",
    "    incorrect = 1\n",
    "    normal = 2\n",
    "\n",
    "class GenderLabels:\n",
    "    male = 0\n",
    "    female = 1\n",
    "\n",
    "class AgeGroup:\n",
    "    map_label = lambda x: 0 if int(x) < 30 else 1 if int(x) < 60 else 2\n",
    "\n",
    "class MaskBaseDataset(Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1.jpg\": MaskLabels.mask,\n",
    "        \"mask2.jpg\": MaskLabels.mask,\n",
    "        \"mask3.jpg\": MaskLabels.mask,\n",
    "        \"mask4.jpg\": MaskLabels.mask,\n",
    "        \"mask5.jpg\": MaskLabels.mask,\n",
    "        \"incorrect_mask.jpg\": MaskLabels.incorrect,\n",
    "        \"normal.jpg\": MaskLabels.normal\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "        \n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        for profile in profiles:\n",
    "            for file_name, label in self._file_names.items():\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)  \n",
    "                if os.path.exists(img_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(label)\n",
    "\n",
    "                    id, gender, race, age = profile.split(\"_\")\n",
    "                    gender_label = getattr(GenderLabels, gender)\n",
    "                    age_label = AgeGroup.map_label(age)\n",
    "\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image)\n",
    "            \n",
    "        return image_transform, multi_class_label\n",
    "    def encode_multi_class(self, mask, gender, age):\n",
    "        return mask * 6 + gender * 3 + age\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers):\n",
    "    # 인자로 전달받은 dataset에서 train_idx에 해당하는 Subset 추출\n",
    "    train_set = torch.utils.data.Subset(dataset,\n",
    "                                        indices=train_idx)\n",
    "    # 인자로 전달받은 dataset에서 valid_idx에 해당하는 Subset 추출\n",
    "    val_set   = torch.utils.data.Subset(dataset,\n",
    "                                        indices=valid_idx)\n",
    "    \n",
    "    # 추출된 Train Subset으로 DataLoader 생성\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    # 추출된 Valid Subset으로 DataLoader 생성\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # 생성한 DataLoader 반환\n",
    "    return train_loader, val_loader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data_dir = '../input/data/train'\n",
    "img_dir = f'{data_dir}/images'\n",
    "df_path = f'{data_dir}/train.csv'\n",
    "\n",
    "dataset = MaskBaseDataset(img_dir)\n",
    "dataset_labels = [dataset.encode_multi_class(mask, gender, age) for mask, gender, age in zip(dataset.mask_labels, dataset.gender_labels, dataset.age_labels)]\n",
    "\n",
    "# train : test = 8 : 2\n",
    "n_test = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_test\n",
    "train_dataset, test_dataset = data.random_split(dataset, [n_train, n_test])\n",
    "train_labels, test_labels = data.random_split(dataset_labels, [n_train, n_test])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    transforms.RandomHorizontalFlip(p=1.0)\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    CenterCrop(224),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# 각 dataset에 augmentation 함수를 설정합니다.\n",
    "train_dataset.dataset.set_transform(transform)\n",
    "test_dataset.dataset.set_transform(transform)\n",
    "\n",
    "# test data loader\n",
    "test_loader = data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def train(args, model, train_loader, optimizer, scheduler, criterion, writer):\n",
    "    model.train()\n",
    "    \n",
    "    corrects, scores, running_loss  = 0., 0., 0.\n",
    "    n_iter = 0\n",
    "    for step, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(args.device)\n",
    "        labels = labels.to(args.device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if step % args.log_steps == 0:\n",
    "            print(f\"Training Steps: {step} Loss: {str(loss.item())}\")\n",
    "        \n",
    "        _,preds = torch.max(outputs, 1)\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "        running_loss += loss.item() * images.size(0) \n",
    "        scores += sklearn.metrics.f1_score(labels.data.cpu().numpy(),preds.cpu().numpy(),average='macro')\n",
    "        n_iter +=1\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    acc = corrects / len(train_loader.dataset) * 100\n",
    "    f1_scores = scores / n_iter\n",
    "    print(f'Train Loss:{train_loss} acc:{acc} F1-score:{scores}')\n",
    "    return model, train_loss, acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def validate(args, model, valid_loader,criterion, writer):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    corrects, scores, running_loss  = 0., 0., 0.\n",
    "    n_iter = 0\n",
    "    for step, (images,labels) in enumerate(valid_loader):\n",
    "        images = images.to(args.device)\n",
    "        labels = labels.to(args.device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        _,preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_predictions.extend(preds.cpu().numpy())\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "        running_loss += loss.item() * images.size(0) \n",
    "        scores += sklearn.metrics.f1_score(labels.data.cpu().numpy(),preds.cpu().numpy(),average='macro')\n",
    "        n_iter +=1\n",
    "        \n",
    "    valid_loss = running_loss / len(valid_loader.dataset)\n",
    "    acc = corrects / len(valid_loader.dataset) * 100\n",
    "    f1_scores = scores / n_iter\n",
    "    print(f'Valid Loss:{valid_loss} Valid Acc:{acc} F1-score:{f1_scores}')\n",
    "    return valid_loss, acc, f1_scores, all_predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "n_splits = 5\n",
    "\n",
    "def ensemble_kfold(args, train_dataset, train_labels, test_dataset, n_splits = 5):\n",
    "    tensor_name = args.model_name + '0921'\n",
    "    writer = SummaryWriter(tensor_name)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    counter = 0\n",
    "    patience = 10\n",
    "    accumulation_steps = 2\n",
    "    best_val_acc = 0\n",
    "    best_val_loss = np.inf\n",
    "    train_oof_pred = None\n",
    "    test_oof_pred = None\n",
    "    final_oof_pred = None\n",
    "    \n",
    "    # K-Fold Cross Validation과 동일하게 Train, Valid Index를 생성합니다. \n",
    "    for i, (train_idx, valid_idx) in enumerate(skf.split(train_dataset,train_labels)):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f'k-fold:{i+1}')\n",
    "        \n",
    "        # make loader\n",
    "        train_loader, val_loader = getDataloader(train_dataset, train_idx, valid_idx, args.batch_size, 4)\n",
    "        \n",
    "        # -- model\n",
    "        if 'efficient5' in args.model_name:\n",
    "            print('load efficient5')\n",
    "            model = EfficientNet5().to(args.device)\n",
    "        elif 'swin' in args.model_name: \n",
    "            print('load swin')\n",
    "            model = swinLargeModel().to(args.device)\n",
    "        elif 'cait' in args.model_name:\n",
    "            print('load cait')\n",
    "            model = caitBaseModel().to(args.device)\n",
    "        \n",
    "        # -- loss & metric\n",
    "        criterion =nn.CrossEntropyLoss()    \n",
    "        #criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), args.lr, weight_decay=0.0)\n",
    "        #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=1, eta_min=1e-4)\n",
    "\n",
    "        best_acc, best_idx, best_f1 = 0., 0., 0.\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        for epoch in notebook.tqdm(range(args.n_epochs)):\n",
    "            #train\n",
    "            model, train_loss, acc = train(args, model, train_loader, optimizer, scheduler, criterion, writer)\n",
    "            #validate\n",
    "            valid_loss, valid_acc, valid_f1, train_predictions = validate(args, model, val_loader,criterion, writer)\n",
    "            #save the best model\n",
    "            if valid_acc > best_acc and valid_f1 > best_f1:\n",
    "                best_acc = valid_acc\n",
    "                best_idx = epoch\n",
    "                best_f1 = valid_f1\n",
    "                best_model_prediction = train_predictions\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        model.load_state_dict(best_model_wts)\n",
    "        torch.save(model.state_dict(), f\"{args.model_name}_kfold{i+1}_ep{args.n_epochs}_batch{args.batch_size}_lr{args.lr}_{best_acc}.pt\")\n",
    "        \n",
    "        # 각 fold에서 생성된 모델을 사용해 Test 데이터를 예측합니다. \n",
    "        all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,_ in test_loader:\n",
    "                images = images.to(args.device)\n",
    "                # Test Time Augmentation\n",
    "                pred = model(images) / 2 # 원본 이미지를 예측하고\n",
    "                #pred += model(torch.flip(images)) / 2 # flip으로 뒤집어 예측합니다. \n",
    "                all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "            fold_pred = np.array(all_predictions)\n",
    "\n",
    "        # 확률 값으로 앙상블을 진행하기 때문에 'k'개로 나누어줍니다.\n",
    "        if test_oof_pred is None:\n",
    "            test_oof_pred = np.array(fold_pred) / n_splits\n",
    "        else:\n",
    "            test_oof_pred += np.array(fold_pred) / n_splits\n",
    "    \n",
    "    return test_oof_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "config = {}\n",
    "config['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config['n_epochs'] = 20\n",
    "config['batch_size'] = 32\n",
    "config['lr'] = 1e-4\n",
    "config['log_steps'] = 500\n",
    "config['model_name'] = 'swin_large'\n",
    "args = easydict.EasyDict(config)\n",
    "\n",
    "swin_test = ensemble_kfold(args, train_dataset, train_labels, test_loader, n_splits = 5)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}