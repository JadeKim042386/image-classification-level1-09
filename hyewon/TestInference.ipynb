{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "TestInference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import easydict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import Resize, ToTensor, Normalize, CenterCrop\n",
        "\n",
        "import sklearn\n",
        "\n",
        "from tqdm import notebook\n",
        "import gc\n",
        "import random"
      ],
      "outputs": [],
      "metadata": {
        "id": "p82Pr8C3_s7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "\n",
        "seed_everything(42)"
      ],
      "outputs": [],
      "metadata": {
        "id": "1ii77blv_6CL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, img_paths, transform):\n",
        "        self.img_paths = img_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = Image.open(self.img_paths[index])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)"
      ],
      "outputs": [],
      "metadata": {
        "id": "02-ZA0OmA83G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class swinBaseModel(nn.Module):\n",
        "    def __init__(self, class_n=18):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
        "        self.classify = torch.nn.Linear(in_features=1000,out_features=class_n)        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "        x = self.classify(x)\n",
        "        return x\n",
        "    \n",
        "class swinTinyModel(nn.Module):\n",
        "    def __init__(self, class_n=18):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model('swin_tiny_patch4_window7_224',pretrained=True)\n",
        "        self.classify = torch.nn.Linear(in_features=1000,out_features=class_n)        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "        x = self.classify(x)\n",
        "        return x\n",
        "\n",
        "class swinLargeModel(nn.Module):\n",
        "    def __init__(self, class_n=18):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model('swin_large_patch4_window7_224', pretrained=True)\n",
        "        self.classify = torch.nn.Linear(in_features=1000,out_features=class_n)        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "        x = self.classify(x)\n",
        "        return x\n",
        "\n",
        "class EfficientNet7(nn.Module):\n",
        "    def __init__(self, class_n=18):\n",
        "        super().__init__()\n",
        "        self.model = EfficientNet.from_pretrained('efficientnet-b7',class_n)\n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "    \n",
        "class EfficientNet5(nn.Module):\n",
        "    def __init__(self, class_n=18):\n",
        "        super().__init__()\n",
        "        self.model = EfficientNet.from_pretrained('efficientnet-b5',class_n)\n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "class caitBaseModel(nn.Module):\n",
        "    def __init__(self, class_n=18):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model('cait_s24_224',pretrained=True)\n",
        "        self.classify = torch.nn.Linear(in_features=1000,out_features=class_n)        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "        x = self.classify(x)\n",
        "        return x"
      ],
      "outputs": [],
      "metadata": {
        "id": "RP_8Oj7jFeZe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# meta 데이터와 이미지 경로를 불러옵니다.\n",
        "test_dir = './eval'\n",
        "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
        "image_dir = os.path.join(test_dir, 'images')\n",
        "\n",
        "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
        "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
        "transform = transforms.Compose([\n",
        "    CenterCrop(224),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])\n",
        "dataset = TestDataset(image_paths, transform)\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 모델을 정의합니다.\n",
        "device = torch.device('cuda')\n",
        "model = caitBaseModel()\n",
        "model = torch.load('{model_path}')\n",
        "model.eval()\n",
        "\n",
        "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
        "all_predictions = []\n",
        "for images in loader:\n",
        "    with torch.no_grad():\n",
        "        images = images.to(device)\n",
        "        pred = model(images)\n",
        "        pred = pred.argmax(dim=-1)\n",
        "        all_predictions.extend(pred.cpu().numpy())\n",
        "submission['ans'] = all_predictions\n",
        "\n",
        "# 제출할 파일을 저장합니다.\n",
        "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
        "print('test inference is done!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test inference is done!\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxrgVRi0BSpD",
        "outputId": "c2175e9e-6db7-4ee7-94a7-8128ec6b5f0a"
      }
    }
  ]
}